{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = 'adverbly_adjectives'\n",
    "os.makedirs(basepath, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractAdverblyAdjectives(corpusname, textnums, tokens, pos, genres=pd.DataFrame(), bygenre=True):\n",
    "    assert tokens.shape == textnums.shape, \"Tokens must be the same length as the text numbers\"\n",
    "    assert textnums.shape == pos.shape, \"Parts of speech must be the same length as the text numbers\"\n",
    "    if bygenre:\n",
    "        assert genres.shape == tokens.shape, \"Genres must be the same length as the number of texts\"\n",
    "    \n",
    "    print(corpusname)\n",
    "    \n",
    "    corpuspath = basepath + '/' + corpusname \n",
    "    os.makedirs(corpuspath, exist_ok=True)\n",
    "    \n",
    "    if bygenre:\n",
    "        df = pd.concat([genres, textnums, tokens, pos], axis=1)\n",
    "        print(df.head())\n",
    "    else:\n",
    "        df = pd.concat([textnums, tokens, pos], axis=1)\n",
    "    \n",
    "    if bygenre:\n",
    "        \n",
    "        genrespath = corpuspath + '/' + 'genres'\n",
    "        os.makedirs(genrespath, exist_ok=True)\n",
    "        \n",
    "        genre_grouped = df.groupby('genre')\n",
    "        \n",
    "        for genre,genre_group in genre_grouped:\n",
    "            num_tokens = len(genre_group.index)\n",
    "            print(genre, num_tokens)\n",
    "            \n",
    "            grouped = genre_group.groupby('text_num')\n",
    "            \n",
    "            genre_df = pd.DataFrame()\n",
    "\n",
    "            for name,group in grouped:\n",
    "                next_pos = group['pos'][1:].reset_index(drop=True).rename('next_pos')\n",
    "                next_token = group['token'][1:].reset_index(drop=True).rename('next_token')\n",
    "        \n",
    "                group = group.reset_index(drop=True)\n",
    "\n",
    "                # Throw out last word\n",
    "                group = pd.concat([group, next_pos, next_token], axis=1).dropna()\n",
    "                \n",
    "                # Keep only fully alphabetical words\n",
    "                group = group[group['token'].str.isalpha() & group['next_token'].str.isalpha()]\n",
    "                \n",
    "                # Keep only the pairs where the first token ends in ly\n",
    "                group = group[group['token'].str.endswith('ly')]\n",
    "                \n",
    "                # Throw out 'only'\n",
    "                group = group[group['token'] != 'only']\n",
    "                \n",
    "                # Adverbly adjectives!\n",
    "                group = group[(group['pos'] == 'ADV') & (group['next_pos'] == 'ADJ')]\n",
    "                \n",
    "                pair = group['token'].str.cat(group['next_token'], sep=' ').rename('pair')\n",
    "                \n",
    "                genre_df = pd.concat([genre_df, pair], axis=0)\n",
    "            \n",
    "            genre_df = genre_df.rename(columns={0 : 'pairs'})\n",
    "            genre = re.sub('/', '', re.sub(' ', '_', genre))\n",
    "            \n",
    "            final_df = genre_df['pairs'].value_counts().reset_index()\n",
    "            final_df['freqmil'] = (final_df['pairs'] / num_tokens) * 1000000\n",
    "            \n",
    "            final_df.to_csv(genrespath + '/' + genre + '_pairs.csv', header=['pair', 'counts', 'freqmil'], index=None)\n",
    "                \n",
    "    num_tokens = len(df.index)\n",
    "    print(corpusname, num_tokens)\n",
    "\n",
    "    grouped = df.groupby('text_num')\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for name,group in grouped:\n",
    "        next_pos = group['pos'][1:].reset_index(drop=True).rename('next_pos')\n",
    "        next_token = group['token'][1:].reset_index(drop=True).rename('next_token')\n",
    "\n",
    "        group = group.reset_index(drop=True)\n",
    "\n",
    "        # Throw out last word\n",
    "        group = pd.concat([group, next_pos, next_token], axis=1).dropna()\n",
    "\n",
    "        # Keep only fully alphabetical words\n",
    "        group = group[group['token'].str.isalpha() & group['next_token'].str.isalpha()]\n",
    "\n",
    "        # Keep only the pairs where the first token ends in ly\n",
    "        group = group[group['token'].str.endswith('ly')]\n",
    "\n",
    "        # Throw out 'only'\n",
    "        group = group[group['token'] != 'only']\n",
    "\n",
    "        # Adverbly adjectives!\n",
    "        group = group[(group['pos'] == 'ADV') & (group['next_pos'] == 'ADJ')]\n",
    "\n",
    "        pair = group['token'].str.cat(group['next_token'], sep=' ').rename('pair')\n",
    "\n",
    "        df = pd.concat([df, pair], axis=0)\n",
    "\n",
    "    df = df.rename(columns={0 : 'pairs'})\n",
    "    final_df = df['pairs'].value_counts().reset_index()\n",
    "    final_df['freqmil'] = (final_df['pairs'] / num_tokens) * 1000000\n",
    "\n",
    "    final_df.to_csv(corpuspath + '/' + 'all_pairs.csv', header=['pair', 'counts', 'freqmil'], index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  text_num  token    pos\n",
      "0           0         1  magoo   NOUN\n",
      "1           1         1      '  PUNCT\n",
      "2           2         1    was   VERB\n",
      "3           3         1     by    ADP\n",
      "4           4         1    far    ADV\n",
      "Cornell\n",
      "Cornell 1496086\n"
     ]
    }
   ],
   "source": [
    "path = 'pos/'\n",
    "suffix = '_pos.csv'\n",
    "\n",
    "files = [ path+f for f in os.listdir(path) if f.endswith(suffix)]\n",
    "\n",
    "for f in files:\n",
    "    corpusname = f.split(path)[1].split(suffix)[0]\n",
    "    df = pd.read_csv(f)\n",
    "    \n",
    "    df['token'] = df['token'].str.lower()\n",
    "    \n",
    "    print(df.head())\n",
    "    \n",
    "    if 'genre' in df.columns:\n",
    "        extractAdverblyAdjectives(corpusname, df['text_num'], df['token'], df['pos'], df['genre'], bygenre=True)\n",
    "    else:\n",
    "        extractAdverblyAdjectives(corpusname, df['text_num'], df['token'], df['pos'], bygenre=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specially dealing with COCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_dict = {\n",
    "    'spok' : 'Spoken',\n",
    "    'mag' : 'Magazine',\n",
    "    'acad' : 'Academic',\n",
    "    'news' : 'News',\n",
    "    'fic' : 'Fiction'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['COCA/POS/acad.zip', 'COCA/POS/news.zip', 'COCA/POS/fic.zip', 'COCA/POS/mag.zip', 'COCA/POS/spok.zip']\n"
     ]
    }
   ],
   "source": [
    "pos_path = 'COCA/POS/'\n",
    "zipfiles = [pos_path+f for f in os.listdir(pos_path) if f.endswith('.zip')]\n",
    "print(zipfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic 120484732\n",
      "News 125553380\n",
      "Fiction 125360785\n",
      "Magazine 127689724\n",
      "Spoken 131059025\n"
     ]
    }
   ],
   "source": [
    "def deleteDir(dir):\n",
    "    try:\n",
    "        for f in os.listdir(dir):\n",
    "            os.remove(dir+f)\n",
    "        os.rmdir(dir)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "genre_count = defaultdict(int)\n",
    "\n",
    "tmp_dir = '__tmp/'\n",
    "\n",
    "deleteDir(tmp_dir)\n",
    "\n",
    "for f in zipfiles:\n",
    "    os.makedirs(tmp_dir)\n",
    "    \n",
    "    genre = genre_dict[f.split('/')[-1].split('.zip')[0]]\n",
    "    with ZipFile(f, 'r') as zip_f:\n",
    "        zip_f.extractall(tmp_dir)\n",
    "    \n",
    "    lines = 0\n",
    "    for f in os.listdir(tmp_dir):\n",
    "        with open(tmp_dir+f, 'r', encoding='latin-1') as fo:\n",
    "            for l in fo:\n",
    "                if not l.startswith('##'):\n",
    "                    lines += 1\n",
    "    \n",
    "    genre_count[genre] = lines\n",
    "    \n",
    "    print(genre, genre_count[genre])\n",
    "    deleteDir(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fiction\n",
      "News\n",
      "Magazine\n",
      "Academic\n",
      "Spoken\n"
     ]
    }
   ],
   "source": [
    "advadj_path = 'COCA/all_years/'\n",
    "corpusname = 'COCA'\n",
    "\n",
    "advadj_files = [advadj_path+f for f in os.listdir(advadj_path) if f.endswith('.csv')]\n",
    "\n",
    "for f in advadj_files:\n",
    "    allGenres = False\n",
    "    \n",
    "    split = f.split('/')[-1].split('.csv')[0].split('_')\n",
    "    if len(split) == 3:\n",
    "        genre = genre_dict[split[0]]\n",
    "    else:\n",
    "        allGenres = True\n",
    "    \n",
    "    df = pd.read_csv(f).rename(columns={'freq' : 'counts'})\n",
    "    \n",
    "    num_tokens = -1\n",
    "    if allGenres:\n",
    "        num_tokens = sum([genre_count[g] for g in genre_count])\n",
    "    else:\n",
    "        num_tokens = genre_count[genre]\n",
    "    \n",
    "    df['freqmil'] = (df['counts'] / num_tokens) * 1000000\n",
    "    \n",
    "    df.sort_values('counts', ascending=False, inplace=True)\n",
    "    \n",
    "    # Keep only fully alphabetical words\n",
    "    df = df[df['pair'].str.match('[a-zA-Z ]*')]\n",
    "\n",
    "    # Throw out 'only'\n",
    "    df = df[~ df['pair'].str.startswith('only ')]\n",
    "    \n",
    "    corpuspath = basepath + '/' + corpusname \n",
    "    os.makedirs(corpuspath, exist_ok=True)\n",
    "    \n",
    "    genrespath = corpuspath + '/' + 'genres'\n",
    "    os.makedirs(genrespath, exist_ok=True)\n",
    "    \n",
    "    if allGenres:\n",
    "        df.to_csv(corpuspath + '/' + 'all_pairs.csv', header=['pair', 'counts', 'freqmil'], index=None)\n",
    "    else:\n",
    "        print(genre)\n",
    "        df.to_csv(genrespath + '/' + genre + '_pairs.csv', header=['pair', 'counts', 'freqmil'], index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
