{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from bs4 import BeautifulSoup\n",
    "import spacy\n",
    "spacy.load('en_core_web_sm')\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cornell_texts = []\n",
    "with open('cornell_all_reviews.txt', 'r+') as fo:\n",
    "    cornell_texts = fo.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cornell_sent_lengths = []\n",
    "cornell_sent_count = []\n",
    "\n",
    "for text in cornell_texts:\n",
    "    strip = text.strip()\n",
    "    if strip:\n",
    "        doc = nlp(strip)\n",
    "        num_words = 0\n",
    "        num_sents = 0\n",
    "        for s in doc.sents:\n",
    "            num_words += len(s)\n",
    "            num_sents += 1\n",
    "        cornell_sent_lengths.append(num_words)\n",
    "        cornell_sent_count.append(num_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_texts = []\n",
    "with open('movies_all_reviews.txt', 'r+') as fo:\n",
    "    movies_texts = fo.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_sent_lengths = []\n",
    "movies_sent_count = []\n",
    "\n",
    "for text in movies_texts:\n",
    "    strip = text.strip()\n",
    "    if strip:\n",
    "        doc = nlp(strip)\n",
    "        num_words = 0\n",
    "        num_sents = 0\n",
    "        for s in doc.sents:\n",
    "            num_words += len(s)\n",
    "            num_sents += 1\n",
    "        movies_sent_lengths.append(num_words)\n",
    "        movies_sent_count.append(num_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " '\\n',\n",
       " \"both films consist of a predominately male cast . both films follow young men as they illicitly fight the traditional system for their own desires . and both films are seen through the eyes of one narrator , who eventually realizes that these men have to be stopped . while boiler room writer/director ben younger does not get his point across as well as david fincher does for fight club , he does contribute another impressive work to a series of films aiming to represent the new generation . a generation which has seen the internet prosper and where everyone wants to be a millionaire . paying homage to oliver stone's 1987 classic wall street , younger is almost modernizing the tale by using younger , hipper actors to play the greedy villains as opposed to the older , more experienced types . as is true in real life , younger minds are becoming richer and richer from their knowledge of more standard technology . boiler room dismisses the notion of ingenuity and shows that greed and desire for power come in all ages . another similarity with fight club is that both films are not action flicks . some people are convinced that an all-male cast automatically means there must be gory violence , here is proof that this is not true . if you want to see an action movie starring ben affleck , go see reindeer games this weekend . if you want to see a smart , insightful film with excellent acting and a clever script , see boiler room . giovanni ribisi gives an outstanding performance as the film's narrator , seth . after dropping out of college and running a lucrative gambling center for college students in his apartment , seth is offered a high paying job by a wealthy man ( nicky katt ) . he agrees to take the job ( in which you are guaranteed to become a millionaire within three years ) of selling stock to well-off americans from the mid-west over the telephone and begins to fit in quite well with his co-workers . learning tricky techniques to deceive innocent people into buying shares of a good in production , seth figures this is too good to be true . after stumbling into a room at the wrong time , he knows there is something no good about this company . at this point , seth is left with the ultimate choice ; continue with the american dream and make millions or tell the authorities that something fishy is going on . ribisi is believable as seth especially when he shares scenes with ron rifkin , playing seth's dad . the two have perfect chemistry as a troubled father and son trying to impress each other and simultaneously impress themselves . the transitions from anger to sympathy that these scenes contain are the standout segments of the entire film . the supporting cast of greedy co-workers is also flawless . ben affleck shines in a short but sweet performance as a recruiter for the company , nicky katt is fabulous as the ostensibly friendly boss who eventually becomes extremely jealous of seth , and vin diesel gives his best performance of his career as the foil character of nicky katt . the energy of the cast as a whole makes boiler room well paced and never boring . the only major error in the film is that nothing major happens . there is no big plot twist or climatic point to make the film more memorable . due to the lack of a major event , boiler room never finds a suitable genre to fit into . the movie is not intense enough to be a thriller , the romantic segments involving seth and abby ( nia long ) are not properly finalized , and the dialogue isn't funny enough to make it a comedy . in having trouble to characterize the movie as a whole , boiler room is slightly confused at times . it doesn't seem to know which category to fit itself into . one satisfying concluding scene could have changed the whole film for the better . otherwise , the movie is fun to watch thanks to its lively cast of young actors .\\n\",\n",
       " '\\n',\n",
       " 'now before you go assuming i\\'m some sort of high brow snob , who can\\'t appreciate a little dumb humor , let me say that i love cheap humor . i thought there\\'s something about mary was one of the funniest films that i have ever seen and it was certainly one of the best films of 1998 . low brow adolescent humor can be a lot of fun , the problem with the waterboy is that it is just low brow and adolescent , there is no humor component . i wanted to like the waterboy , i really did . i think i only laughed maybe 2 or 3 times throughout the entire movie . actually , i smiled a couple of more times on top of that . not a great record for a 90-minute film . the problem with the waterboy is the same as most other adam sandler movies . those responsible for this mess seem to think that the sheer fact that sandler walks around using a goofy voice and playing dumb the entire movie is a substitute for actual funny material . nothing could be further from the truth , as matter of fact , sandler\\'s idiot voice started to get on my nerves at points in this film . it\\'s really a shame too , because this film had the potential to be very funny . i personally believe that sandler is probably a very talented comedian , it\\'s just that so far he hasn\\'t been able to find the right film to showcase his talents . if his only talent is making goofy voices and playing morons , my guess is that his career in the movies will go down the same road as the vast majority of the former stars of saturday night live . most of whom are now happily no longer in the entertainment industry . sandler plays a 31-year-old , somewhat mentally challenged , waterboy for a college football team . the team\\'s somewhat mentally disturbed coach ( henry winkler ) realizes that his waterboy has a great deal of pent-up rage , which , if harnessed properly , would make him a force to be reckoned with on the football field . you can figure out the rest from here . sandler joins the team and this once lowly waterboy becomes a football star . as i said , the film had a great deal of potential . the idea was a decent one , but the main potential of this movie is a result of the cast . all of whom are very good , just hamstrung by really , really , lousy material . even sandler , annoying goofy voice and all , has enough charisma and natural comedic ability to overcome some of his bad material . even as unfunny as his character is , i still found myself rooting for him throughout the film . but it is the supporting cast that i feel most badly about . if their material had been just a bit better , this film could have been such a funny movie . fairuza balk plays sandler\\'s leather-wearing biker-chick love interest and does a great job playing sleazy and sexy at the same time . winkler is great as the coach who uses a \" coaching for dummies \" -style book to help him get through games . the real standout though , is kathy bates . even with some of the worst material of her career to deal with , she is still a treat to watch in her role as sandler\\'s overprotective and overbearing mama . even with the performances of bates and winkler , there is absolutely no way i would recommend this movie . although i get the distinct impression that without them , this film would have ranked in negative numbers for me . which is sad , because i can\\'t really put my finger on a particular element of the movie and single it out as the cause of the disaster that it became . it\\'s obvious that those involved , specifically the actors , tried very hard to make what they thought was going to be a funny movie . it\\'s just too bad that 99 percent of all of the jokes fell flat .\\n']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cornell_texts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Aug. 2, 2007 Watchers who warned that a six-year gap between installments would cost the \\'Rush Hour\\' franchise some energy \\' especially from Jackie Chan, now in his early 50s \\' aren\\'t entirely off the mark. But the latest picture to feature one of the movies\\' oddest crime-fighting tandems nevertheless stays true to the franchise formula of East-West fusion action, broad cultural comedy and international intrigue, this time largely in Paris. August rollout is like money in the bank for New Line, which will milk this likely final installment for maximum revenues down the ancillary stream. Though late summer timing is just right for the franchise, \"Rush Hour 3\" opens just a week after \"The Bourne Ultimatum,\" and while auds may take some relief in the bouncy comic rapport between Chan and Chris Tucker, they\\'re bound to find the action mild if not downright tame by comparison. The action bar has been raised to exceptional heights -- higher than even the great Chan can leap across. It may take younger viewers awhile to figure out the background plot in the new pic, since screenwriter Jeff Nathanson (who also wrote the superior \"Rush Hour 2\") revives characters from the first \"Rush Hour\": Chinese Ambassador Han (Tzi Ma) and his now-20-year-old daughter Soo Yung (now played by Zhang Jingchu, from \"Peacock\" and \"Seven Swords\"). Han is shot by an assassin in Los Angeles just as he\\'s ready to blow the cover on a secret triad conspiracy before the World Criminal Court. Carter (Tucker) has been demoted by the LAPD to mere traffic cop, a job he executeswith his usual soul-hipster musical-comedy flair. As bodyguard to Han, Lee chases the assassin across downtown Los Angeles freeway ramps and bridges (where Chan has a few minutes for impressive stunt work that doesn\\'t involve hand-to-hand or foot-to-foot combat), only to discover the culprit is Kenji (the busy Hiroyuki Sanada), his long-lost companion and \"brother\" from their childhood orphanage. Emotionally unable to shoot Kenji, Lee lets him get away. This sets up a potentially more interesting personal conflict for Lee than in \"Rush Hour 2,\" in which his character had to confront his father\\'s ex-partner and murderer. It\\'s not to be, however: The Lee-Kenji battle never goes beyond the emotional level of a stare-off. Carter and Lee hunt down an envelope with key info on the triad conspiracy. Until recently, the evidence had been under Soo Yung\\'s care at her kung fu studio in Chinatown (where the guys have a hilarious run-in with a giant dude played wordlessly by Sun Ming Ming, who makes Yao Ming look like a runt). Triad henchmen now have the envelope, but with a little bit of (witty) torture, the duo determine the truth lies with Genevieve (the exotic Noemie Lenoir), the star attraction at an underground Paris nitery. The old black-Asian cultural parries between Lee and Carter have been retired; now in Paris, it\\'s Americans vs. the French --hence characters like stuck-up taxi driver George (Yves Attal), who\\'s so Americanized he dons a Lakers cap and thinks he\\'s an international spy. Shift is a bit of a stretch, but the Gallic friction is made more amusing by Roman Polanski (making a terrific uncredited cameo as Paris\\' sadistic police chief) and the wonderful Julie Depardieu as George\\'s highly skeptical wife. Also involved in all this is World Criminal Court topper Reynard (Max Von Sydow), who may or may not be the upholder of global justice his title suggests. By the time Kenji phones Lee for a final confab at the Eiffel Tower, two things will be obvious to attentive viewers: Pic is following the always-compact \"Rush Hour\" formula, down to wrapping things up in less than 90 minutes\\' playing time; and Chan has far fewer stunt set pieces here than in any previous film in which he\\'s starred. Jumps, thrusts and falls across and down the Eiffel are quite impressive, despite a few visible CGI effects, and the capper stunt involving a giant French flag is just goofy enough. Still, the pic ends rather flatly; the previous adrenaline rush just isn\\'t there anymore. As if to compensate for an understandable diminution of physical prowess and martial artistry, Chan moves more aggressively into purely comic territory, offering a preview of his second career as a comedy star. By contrast, Tucker\\'s shtick is starting to feel long in the tooth, and the thesp feels increasingly like a second fiddle. Sanada, always a strong presence, has an underwritten role that cheats the pic of several juicy action and psychodrama possibilities. Lenoir and Attal uphold their Gallic pride, while Von Sydow plays the role Hollywood has regularly tagged to this supremely great actor: The Elegant European. Helmer Ratner knows the \"Rush Hour\" routine by heart, and production values, even with several new contributors to the franchise (including solid lenser J. Michael Muro), maintain the franchise\\'s sharp, shiny look.\\n',\n",
       " '\\n',\n",
       " \"Aug 30, 2006 As modest as a mash note scrawled by a very shy English major onto a bar napkin, Funny Ha Ha , the first movie written and directed by Andrew Bujalski, was hailed as the fresh voice of a generation. If you see his follow-up, the charming if a wee-bit-too-wee Mutual Appreciation , you'll know why. Bujalski's characters still talk in spilled ironic fragments, rationalizing their tiniest impulses (for a kiss, a joke, a beer), turning every thought, every moment, into a coyly halting ''creative'' observation. This time, though, Bujalski works in streaky black and white, looking back all the more to Cassavetes and the Left Bank conversational epic The Mother and the Whore . The central figure, Alan (Justin Rice), with his bed head and his grin of shy vanity, is an aspiring indie rocker, which means that he has a ''band'' that consists of whomever he happens to be jamming with that week, at gigs attended mostly by his friends. In Brooklyn, Alan is staying with an old buddy, Lawrence (played by Bujalski), who's like Gary Dell'Abate as a young computer geek, and he also has a quasi-flirtation going with Lawrence's girlfiend, Ellie (Rachel Clift), who treats her romantic desires as an inconvenience, a disruption of the nervous, stuttery we're-all-boho-comrades-here style she wears like armor. If this is the sound of a new generation, then it may be the first generation cautious enough to embrace friendship as mightier than love.\\n\",\n",
       " '\\n',\n",
       " \"Tuesday, Dec 12 2006 Given what an awful stiff Somerset Maugham can be, it's remarkable how many movies have been made of his uptight tales of civil servants sweating it out in British colonies (48 for the big screen alone). John Curran 's fresh take on Maugham's novel The Painted Veil , from a crisp script by Philadelphia screenwriter Ron Nyswaner , is sober and delicate but downright buoyant compared to a dull 1934 adaptation starring a miscast Greta Garbo , and a 1957 remake, The Seventh Sin , that tanked on arrival. Edward Norton makes a pretty impressive stiff himself as Walter, a research doctor who, after marrying up and badly to bored socialite Kitty (a suitably brittle Naomi Watts ), moves to Shanghai , where he immerses himself in the study of infectious disease, while she immerses herself in a caddish vice-consul (Liev Schreiber ). Galvanized out of his insipid servility by jealous rage, Walter hauls the missus off to a cholera-ridden rural outpost, where the two gradually defrost in mutual devotion to duty. Bolstered by a strong ensemble Infamous 's Toby Jones as a deputy commissioner gone native, and a wonderfully wrinkled Diana Rigg as a Mother Superior, speaking up for disillusioned decencyand by the ecstatic cinematography of Stuart Dryburgh , The Painted Veil lifts Maugham's story clear of its prissy, attenuated spirituality, and into genuine passion.\\n\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_texts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.674497203740472"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(cornell_sent_lengths) / sum(cornell_sent_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.91007615532716"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(movies_sent_lengths) / sum(movies_sent_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vgautam/.local/lib/python3.5/site-packages/numpy/lib/arraysetops.py:522: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "cornell_df = pd.read_csv('pos/Cornell_pos.csv', index_col=0).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_num</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>magoo</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>'</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>was</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>by</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>far</td>\n",
       "      <td>ADV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_num  token    pos\n",
       "0         1  magoo   NOUN\n",
       "1         1      '  PUNCT\n",
       "2         1    was   VERB\n",
       "3         1     by    ADP\n",
       "4         1    far    ADV"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cornell_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vgautam/.local/lib/python3.5/site-packages/numpy/lib/arraysetops.py:522: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "movies_df = pd.read_csv('pos/Movies_pos.csv', index_col=0).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_num</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Sep</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2007</td>\n",
       "      <td>NUM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_num    token    pos\n",
       "0         0  Tuesday  PROPN\n",
       "1         0        ,  PUNCT\n",
       "2         0      Sep  PROPN\n",
       "3         0       18    NUM\n",
       "4         0     2007    NUM"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.006302449392916"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cornell_df['token'].str.len().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.170183282992839"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df['token'].str.len().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relative frequency of 'film' and 'pic' and 'I'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006090563036191126"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cornell_df[cornell_df['token'].str.lower() == 'film']) / len(cornell_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0025482685976582595"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movies_df[movies_df['token'].str.lower() == 'film']) / len(movies_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.678878539655167e-06"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cornell_df[cornell_df['token'].str.lower() == 'pic']) / len(cornell_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0006290527247239376"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movies_df[movies_df['token'].str.lower() == 'pic']) / len(movies_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005574549574389156"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cornell_df[cornell_df['token'].str.lower() == 'i']) / len(cornell_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0012362382774443092"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movies_df[movies_df['token'].str.lower() == 'i']) / len(movies_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lexical diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexdiv = []\n",
    "\n",
    "for text in cornell_texts:\n",
    "    strip = text.strip()\n",
    "    if strip:\n",
    "        doc = nlp(strip)\n",
    "\n",
    "        numtokens = 0\n",
    "        types = set()\n",
    "        \n",
    "        for s in doc.sents:\n",
    "            for w in s:\n",
    "                if not re.match('[^a-zA-Z]+$', w.text):\n",
    "                    numtokens += 1\n",
    "                    types.add(w.text)\n",
    "                    \n",
    "        lexdiv.append(len(types)/numtokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5335532169077012"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(lexdiv)/len(lexdiv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexdiv = []\n",
    "\n",
    "for text in movies_texts:\n",
    "    strip = text.strip()\n",
    "    if strip:\n",
    "        doc = nlp(strip)\n",
    "\n",
    "        numtokens = 0\n",
    "        types = set()\n",
    "        \n",
    "        for s in doc.sents:\n",
    "            for w in s:\n",
    "                if not re.match('[^a-zA-Z]+$', w.text):\n",
    "                    numtokens += 1\n",
    "                    types.add(w.text)\n",
    "                    \n",
    "        lexdiv.append(len(types)/numtokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6367346200111095"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(lexdiv)/len(lexdiv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word and POS unigrams and bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = pd.read_csv('smart.csv', header=None, names=['stopword']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cornell_denominator = len(cornell_df['token'].str.isalpha().index)\n",
    "movies_denominator = len(movies_df['token'].str.isalpha().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unigram</th>\n",
       "      <th>counts</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>337960</td>\n",
       "      <td>225896.255895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VERB</td>\n",
       "      <td>231400</td>\n",
       "      <td>154670.356297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PUNCT</td>\n",
       "      <td>207112</td>\n",
       "      <td>138435.984586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADJ</td>\n",
       "      <td>155540</td>\n",
       "      <td>103964.681151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADP</td>\n",
       "      <td>153692</td>\n",
       "      <td>102729.457217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DET</td>\n",
       "      <td>143253</td>\n",
       "      <td>95751.912492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ADV</td>\n",
       "      <td>98739</td>\n",
       "      <td>65998.255447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PRON</td>\n",
       "      <td>58717</td>\n",
       "      <td>39247.101602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CCONJ</td>\n",
       "      <td>47373</td>\n",
       "      <td>31664.644723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PART</td>\n",
       "      <td>40859</td>\n",
       "      <td>27310.614036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NUM</td>\n",
       "      <td>13692</td>\n",
       "      <td>9151.886424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PROPN</td>\n",
       "      <td>2635</td>\n",
       "      <td>1761.263565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>2521</td>\n",
       "      <td>1685.064685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>X</td>\n",
       "      <td>1471</td>\n",
       "      <td>983.232905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SYM</td>\n",
       "      <td>1121</td>\n",
       "      <td>749.288978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unigram  counts           freq\n",
       "0     NOUN  337960  225896.255895\n",
       "1     VERB  231400  154670.356297\n",
       "2    PUNCT  207112  138435.984586\n",
       "3      ADJ  155540  103964.681151\n",
       "4      ADP  153692  102729.457217\n",
       "5      DET  143253   95751.912492\n",
       "6      ADV   98739   65998.255447\n",
       "7     PRON   58717   39247.101602\n",
       "8    CCONJ   47373   31664.644723\n",
       "9     PART   40859   27310.614036\n",
       "10     NUM   13692    9151.886424\n",
       "11   PROPN    2635    1761.263565\n",
       "12    INTJ    2521    1685.064685\n",
       "13       X    1471     983.232905\n",
       "14     SYM    1121     749.288978"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cornell_pos_counts = cornell_df['pos'].value_counts().reset_index().rename({'pos':'counts','index':'unigram'}, axis=1)\n",
    "cornell_pos_counts['freq'] = cornell_pos_counts['counts'] / cornell_denominator * 1000000\n",
    "cornell_pos_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unigram</th>\n",
       "      <th>counts</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>film</td>\n",
       "      <td>9112</td>\n",
       "      <td>6090.563036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>movie</td>\n",
       "      <td>5435</td>\n",
       "      <td>3632.814980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>time</td>\n",
       "      <td>2319</td>\n",
       "      <td>1550.045619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>good</td>\n",
       "      <td>2316</td>\n",
       "      <td>1548.040385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>story</td>\n",
       "      <td>2090</td>\n",
       "      <td>1396.979450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>character</td>\n",
       "      <td>1988</td>\n",
       "      <td>1328.801505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>characters</td>\n",
       "      <td>1824</td>\n",
       "      <td>1219.182065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>make</td>\n",
       "      <td>1596</td>\n",
       "      <td>1066.784307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>life</td>\n",
       "      <td>1518</td>\n",
       "      <td>1014.648232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>plot</td>\n",
       "      <td>1439</td>\n",
       "      <td>961.843746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       unigram  counts         freq\n",
       "14        film    9112  6090.563036\n",
       "26       movie    5435  3632.814980\n",
       "61        time    2319  1550.045619\n",
       "62        good    2316  1548.040385\n",
       "68       story    2090  1396.979450\n",
       "70   character    1988  1328.801505\n",
       "78  characters    1824  1219.182065\n",
       "85        make    1596  1066.784307\n",
       "90        life    1518  1014.648232\n",
       "97        plot    1439   961.843746"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cornell_tok_counts = cornell_df['token'].value_counts().reset_index().rename({'token':'counts','index':'unigram'}, axis=1)\n",
    "\n",
    "_alpha = cornell_tok_counts[cornell_tok_counts['unigram'].str.isalpha()]\n",
    "_merged = _alpha.merge(stopwords, left_on='unigram', right_on='stopword', how='left', indicator=True)\n",
    "cornell_tok_counts = _merged[_merged['_merge'] == 'left_only'][['unigram', 'counts']]\n",
    "cornell_tok_counts['freq'] = cornell_tok_counts['counts'] / cornell_denominator * 1000000\n",
    "cornell_tok_counts.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>counts</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>special effects</td>\n",
       "      <td>372</td>\n",
       "      <td>248.648974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>high school</td>\n",
       "      <td>163</td>\n",
       "      <td>108.951029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>star wars</td>\n",
       "      <td>157</td>\n",
       "      <td>104.940562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>takes place</td>\n",
       "      <td>115</td>\n",
       "      <td>76.867290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>star trek</td>\n",
       "      <td>115</td>\n",
       "      <td>76.867290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>supporting cast</td>\n",
       "      <td>111</td>\n",
       "      <td>74.193645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>science fiction</td>\n",
       "      <td>109</td>\n",
       "      <td>72.856823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>running time</td>\n",
       "      <td>105</td>\n",
       "      <td>70.183178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>years ago</td>\n",
       "      <td>100</td>\n",
       "      <td>66.841122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>action sequences</td>\n",
       "      <td>94</td>\n",
       "      <td>62.830655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             bigram  counts        freq\n",
       "0   special effects     372  248.648974\n",
       "1       high school     163  108.951029\n",
       "2         star wars     157  104.940562\n",
       "3       takes place     115   76.867290\n",
       "4         star trek     115   76.867290\n",
       "5   supporting cast     111   74.193645\n",
       "6   science fiction     109   72.856823\n",
       "7      running time     105   70.183178\n",
       "8         years ago     100   66.841122\n",
       "9  action sequences      94   62.830655"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cornell_df['next_pos'] = cornell_df['pos'].shift(-1)\n",
    "cornell_df['next_token'] = cornell_df['token'].shift(-1)\n",
    "\n",
    "_alpha = cornell_df[cornell_df['token'].str.isalpha() & cornell_df['next_token'].str.isalpha()]\n",
    "_merged = _alpha.merge(stopwords, left_on='token', right_on='stopword', how='left', indicator='indicator1')\n",
    "_merged = _merged.merge(stopwords, left_on='next_token', right_on='stopword', how='left', indicator='indicator2')\n",
    "cornell_tok_bi_counts = _merged[(_merged['indicator1'] == 'left_only') & (_merged['indicator2'] == 'left_only')][['token', 'next_token']]\n",
    "cornell_tok_bi_counts['bigram'] = cornell_tok_bi_counts['token'].str.cat(cornell_tok_bi_counts['next_token'], sep=' ')\n",
    "cornell_tok_bi_counts = cornell_tok_bi_counts['bigram'].value_counts().reset_index().rename({'bigram':'counts','index':'bigram'}, axis=1)\n",
    "cornell_tok_bi_counts['freq'] = cornell_tok_bi_counts['counts'] / cornell_denominator * 1000000\n",
    "\n",
    "cornell_tok_bi_counts.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>counts</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NOUN PUNCT</td>\n",
       "      <td>109997</td>\n",
       "      <td>73523.228961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADJ NOUN</td>\n",
       "      <td>86144</td>\n",
       "      <td>57579.616131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DET NOUN</td>\n",
       "      <td>84451</td>\n",
       "      <td>56447.995936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NOUN ADP</td>\n",
       "      <td>63355</td>\n",
       "      <td>42347.192840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADP DET</td>\n",
       "      <td>59983</td>\n",
       "      <td>40093.310206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NOUN VERB</td>\n",
       "      <td>55045</td>\n",
       "      <td>36792.695602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NOUN NOUN</td>\n",
       "      <td>47858</td>\n",
       "      <td>31988.824164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PRON VERB</td>\n",
       "      <td>40849</td>\n",
       "      <td>27303.929924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DET ADJ</td>\n",
       "      <td>39131</td>\n",
       "      <td>26155.599448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>VERB DET</td>\n",
       "      <td>38103</td>\n",
       "      <td>25468.472714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bigram  counts          freq\n",
       "0  NOUN PUNCT  109997  73523.228961\n",
       "1    ADJ NOUN   86144  57579.616131\n",
       "2    DET NOUN   84451  56447.995936\n",
       "3    NOUN ADP   63355  42347.192840\n",
       "4     ADP DET   59983  40093.310206\n",
       "5   NOUN VERB   55045  36792.695602\n",
       "6   NOUN NOUN   47858  31988.824164\n",
       "7   PRON VERB   40849  27303.929924\n",
       "8     DET ADJ   39131  26155.599448\n",
       "9    VERB DET   38103  25468.472714"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cornell_df['bigram'] = cornell_df['pos'].str.cat(cornell_df['next_pos'], sep=' ')\n",
    "cornell_pos_bi_counts = cornell_df['bigram'].value_counts().reset_index().rename({'bigram':'counts','index':'bigram'}, axis=1)\n",
    "\n",
    "cornell_pos_bi_counts['freq'] = cornell_pos_bi_counts['counts'] / cornell_denominator * 1000000\n",
    "\n",
    "cornell_pos_bi_counts.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "_lowered = movies_df\n",
    "_lowered['token'] = movies_df['token'].str.lower()\n",
    "movies_df = _lowered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unigram</th>\n",
       "      <th>counts</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>887201</td>\n",
       "      <td>188355.115230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PUNCT</td>\n",
       "      <td>711281</td>\n",
       "      <td>151006.834659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VERB</td>\n",
       "      <td>606224</td>\n",
       "      <td>128702.956123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADP</td>\n",
       "      <td>496493</td>\n",
       "      <td>105406.775044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADJ</td>\n",
       "      <td>474065</td>\n",
       "      <td>100645.251416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PROPN</td>\n",
       "      <td>432579</td>\n",
       "      <td>91837.664060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DET</td>\n",
       "      <td>407317</td>\n",
       "      <td>86474.474747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ADV</td>\n",
       "      <td>245750</td>\n",
       "      <td>52173.373979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CCONJ</td>\n",
       "      <td>146270</td>\n",
       "      <td>31053.507271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PART</td>\n",
       "      <td>126144</td>\n",
       "      <td>26780.704323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PRON</td>\n",
       "      <td>113198</td>\n",
       "      <td>24032.234335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NUM</td>\n",
       "      <td>53268</td>\n",
       "      <td>11308.937071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>3382</td>\n",
       "      <td>718.007531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SYM</td>\n",
       "      <td>3004</td>\n",
       "      <td>637.757133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SPACE</td>\n",
       "      <td>2848</td>\n",
       "      <td>604.637921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>X</td>\n",
       "      <td>1233</td>\n",
       "      <td>261.769156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unigram  counts           freq\n",
       "0     NOUN  887201  188355.115230\n",
       "1    PUNCT  711281  151006.834659\n",
       "2     VERB  606224  128702.956123\n",
       "3      ADP  496493  105406.775044\n",
       "4      ADJ  474065  100645.251416\n",
       "5    PROPN  432579   91837.664060\n",
       "6      DET  407317   86474.474747\n",
       "7      ADV  245750   52173.373979\n",
       "8    CCONJ  146270   31053.507271\n",
       "9     PART  126144   26780.704323\n",
       "10    PRON  113198   24032.234335\n",
       "11     NUM   53268   11308.937071\n",
       "12    INTJ    3382     718.007531\n",
       "13     SYM    3004     637.757133\n",
       "14   SPACE    2848     604.637921\n",
       "15       X    1233     261.769156"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_pos_counts = movies_df['pos'].value_counts().reset_index().rename({'pos':'counts','index':'unigram'}, axis=1)\n",
    "movies_pos_counts['freq'] = movies_pos_counts['counts'] / movies_denominator * 1000000\n",
    "movies_pos_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>counts</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>movie</td>\n",
       "      <td>12853</td>\n",
       "      <td>2728.725842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>film</td>\n",
       "      <td>12003</td>\n",
       "      <td>2548.268598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>time</td>\n",
       "      <td>6225</td>\n",
       "      <td>1321.583939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>director</td>\n",
       "      <td>4767</td>\n",
       "      <td>1012.046689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>story</td>\n",
       "      <td>4743</td>\n",
       "      <td>1006.951425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>man</td>\n",
       "      <td>4715</td>\n",
       "      <td>1001.006951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>life</td>\n",
       "      <td>4632</td>\n",
       "      <td>983.385832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>good</td>\n",
       "      <td>3745</td>\n",
       "      <td>795.073390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>world</td>\n",
       "      <td>3691</td>\n",
       "      <td>783.609047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>make</td>\n",
       "      <td>3294</td>\n",
       "      <td>699.324899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       token  counts         freq\n",
       "26     movie   12853  2728.725842\n",
       "28      film   12003  2548.268598\n",
       "52      time    6225  1321.583939\n",
       "71  director    4767  1012.046689\n",
       "72     story    4743  1006.951425\n",
       "73       man    4715  1001.006951\n",
       "76      life    4632   983.385832\n",
       "89      good    3745   795.073390\n",
       "90     world    3691   783.609047\n",
       "99      make    3294   699.324899"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_tok_counts = movies_df['token'].value_counts().reset_index().rename({'token':'counts','index':'token'}, axis=1)\n",
    "\n",
    "_alpha = movies_tok_counts[movies_tok_counts['token'].str.isalpha()]\n",
    "_merged = _alpha.merge(stopwords, left_on='token', right_on='stopword', how='left', indicator=True)\n",
    "movies_tok_counts = _merged[_merged['_merge'] == 'left_only'][['token', 'counts']]\n",
    "\n",
    "movies_tok_counts['freq'] = movies_tok_counts['counts'] / movies_denominator * 1000000\n",
    "\n",
    "movies_tok_counts.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>counts</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>running time</td>\n",
       "      <td>1074</td>\n",
       "      <td>228.013036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>high school</td>\n",
       "      <td>618</td>\n",
       "      <td>131.203032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mpaa rating</td>\n",
       "      <td>582</td>\n",
       "      <td>123.560137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>film festival</td>\n",
       "      <td>578</td>\n",
       "      <td>122.710926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>los angeles</td>\n",
       "      <td>544</td>\n",
       "      <td>115.492637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>production designer</td>\n",
       "      <td>529</td>\n",
       "      <td>112.308097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>adult guardian</td>\n",
       "      <td>498</td>\n",
       "      <td>105.726715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>accompanying parent</td>\n",
       "      <td>496</td>\n",
       "      <td>105.302110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>requires accompanying</td>\n",
       "      <td>495</td>\n",
       "      <td>105.089807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>years ago</td>\n",
       "      <td>428</td>\n",
       "      <td>90.865530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  bigram  counts        freq\n",
       "0           running time    1074  228.013036\n",
       "1            high school     618  131.203032\n",
       "2            mpaa rating     582  123.560137\n",
       "3          film festival     578  122.710926\n",
       "4            los angeles     544  115.492637\n",
       "5    production designer     529  112.308097\n",
       "6         adult guardian     498  105.726715\n",
       "7    accompanying parent     496  105.302110\n",
       "8  requires accompanying     495  105.089807\n",
       "9              years ago     428   90.865530"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df['next_pos'] = movies_df['pos'].shift(-1)\n",
    "movies_df['next_token'] = movies_df['token'].shift(-1)\n",
    "\n",
    "_alpha = movies_df[movies_df['token'].str.isalpha() & movies_df['next_token'].str.isalpha()]\n",
    "_merged = _alpha.merge(stopwords, left_on='token', right_on='stopword', how='left', indicator='indicator1')\n",
    "_merged = _merged.merge(stopwords, left_on='next_token', right_on='stopword', how='left', indicator='indicator2')\n",
    "movies_tok_bi_counts = _merged[(_merged['indicator1'] == 'left_only') & (_merged['indicator2'] == 'left_only')][['token', 'next_token']]\n",
    "movies_tok_bi_counts['bigram'] = movies_tok_bi_counts['token'].str.cat(movies_tok_bi_counts['next_token'], sep=' ')\n",
    "movies_tok_bi_counts = movies_tok_bi_counts['bigram'].value_counts().reset_index().rename({'bigram':'counts','index':'bigram'}, axis=1)\n",
    "\n",
    "movies_tok_bi_counts['freq'] = movies_tok_bi_counts['counts'] / movies_denominator * 1000000\n",
    "movies_tok_bi_counts.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>counts</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NOUN PUNCT</td>\n",
       "      <td>284686</td>\n",
       "      <td>60439.589602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADJ NOUN</td>\n",
       "      <td>255576</td>\n",
       "      <td>54259.459728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DET NOUN</td>\n",
       "      <td>211206</td>\n",
       "      <td>44839.591555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NOUN ADP</td>\n",
       "      <td>208092</td>\n",
       "      <td>44178.481132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADP DET</td>\n",
       "      <td>177829</td>\n",
       "      <td>37753.566313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PROPN PUNCT</td>\n",
       "      <td>139840</td>\n",
       "      <td>29688.401291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PROPN PROPN</td>\n",
       "      <td>135472</td>\n",
       "      <td>28761.063356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NOUN VERB</td>\n",
       "      <td>118256</td>\n",
       "      <td>25106.061092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DET ADJ</td>\n",
       "      <td>114339</td>\n",
       "      <td>24274.471648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NOUN NOUN</td>\n",
       "      <td>107177</td>\n",
       "      <td>22753.960134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        bigram  counts          freq\n",
       "0   NOUN PUNCT  284686  60439.589602\n",
       "1     ADJ NOUN  255576  54259.459728\n",
       "2     DET NOUN  211206  44839.591555\n",
       "3     NOUN ADP  208092  44178.481132\n",
       "4      ADP DET  177829  37753.566313\n",
       "5  PROPN PUNCT  139840  29688.401291\n",
       "6  PROPN PROPN  135472  28761.063356\n",
       "7    NOUN VERB  118256  25106.061092\n",
       "8      DET ADJ  114339  24274.471648\n",
       "9    NOUN NOUN  107177  22753.960134"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df['bigram'] = movies_df['pos'].str.cat(movies_df['next_pos'], sep=' ')\n",
    "movies_pos_bi_counts = movies_df['bigram'].value_counts().reset_index().rename({'bigram':'counts','index':'bigram'}, axis=1)\n",
    "\n",
    "movies_pos_bi_counts['freq'] = movies_pos_bi_counts['counts'] / movies_denominator * 1000000\n",
    "\n",
    "movies_pos_bi_counts.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cornell_pos_counts.round(2).to_csv('Cornell_POS.csv', index=None)\n",
    "cornell_pos_bi_counts.round(2).to_csv('Cornell_POS_bigrams.csv', index=None)\n",
    "cornell_tok_counts.round(2).to_csv('Cornell_tokens.csv', index=None)\n",
    "cornell_tok_bi_counts.round(2).to_csv('Cornell_token_bigrams.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_pos_counts.round(2).to_csv('Movies_POS.csv', index=None)\n",
    "movies_pos_bi_counts.round(2).to_csv('Movies_POS_bigrams.csv', index=None)\n",
    "movies_tok_counts.round(2).to_csv('Movies_tokens.csv', index=None)\n",
    "movies_tok_bi_counts.round(2).to_csv('Movies_token_bigrams.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378457\n",
      "80347.42053352928\n"
     ]
    }
   ],
   "source": [
    "print(len(movies_tok_bi_counts[movies_tok_bi_counts['counts'] == 1]))\n",
    "print(len(movies_tok_bi_counts[movies_tok_bi_counts['counts'] == 1]) / movies_denominator * 1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95138\n",
      "63591.30664367332\n"
     ]
    }
   ],
   "source": [
    "print(len(cornell_tok_bi_counts[cornell_tok_bi_counts['counts'] == 1]))\n",
    "print(len(cornell_tok_bi_counts[cornell_tok_bi_counts['counts'] == 1]) / cornell_denominator * 1000000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
