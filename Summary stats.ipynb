{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook calculates summary statistics on all corpora in the `adverbly_adjectives` directory.\n",
    "\n",
    "It assumes POS information is in the `pos` directory, and that hapax legomena lists are in the `hapax_legomena` directory.\n",
    "\n",
    "COCA is special since it's so massive. COCA POS files are handled specially and expected to be in a directory named `COCA/POS`.\n",
    "\n",
    "Summary statistics calculated include the number of words, as well as the number and relative frequencies of adverbly adjective pairs and hapax legomena."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic 120484732\n",
      "News 125553380\n",
      "Fiction 125360785\n",
      "Magazine 127689724\n",
      "Spoken 131059025\n"
     ]
    }
   ],
   "source": [
    "# required to translate the shortened versions of genre names to something that looks better in a summary sheet\n",
    "genre_dict = {\n",
    "    'spok' : 'Spoken',\n",
    "    'mag' : 'Magazine',\n",
    "    'acad' : 'Academic',\n",
    "    'news' : 'News',\n",
    "    'fic' : 'Fiction'\n",
    "}\n",
    "\n",
    "pos_path = 'COCA/POS/'\n",
    "zipfiles = [pos_path+f for f in os.listdir(pos_path) if f.endswith('.zip')]\n",
    "\n",
    "def deleteDir(dir):\n",
    "    try:\n",
    "        for f in os.listdir(dir):\n",
    "            os.remove(dir+f)\n",
    "        os.rmdir(dir)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "coca_genre_count = defaultdict(int)\n",
    "\n",
    "tmp_dir = '__tmp/'\n",
    "\n",
    "deleteDir(tmp_dir)\n",
    "\n",
    "# extract each zip file to a temporary directory and count the number of lines (representing num of words for that genre)\n",
    "for f in zipfiles:\n",
    "    os.makedirs(tmp_dir)\n",
    "    \n",
    "    genre = genre_dict[f.split('/')[-1].split('.zip')[0]]\n",
    "    with ZipFile(f, 'r') as zip_f:\n",
    "        zip_f.extractall(tmp_dir)\n",
    "    \n",
    "    lines = 0\n",
    "    \n",
    "    #  iterate over all files/texts in current genre\n",
    "    for f in os.listdir(tmp_dir):\n",
    "        with open(tmp_dir+f, 'r', encoding='latin-1') as fo:\n",
    "            \n",
    "            # count lines in current file\n",
    "            for l in fo:\n",
    "                if not l.startswith('##'):\n",
    "                    lines += 1\n",
    "    \n",
    "    coca_genre_count[genre] = lines\n",
    "    \n",
    "    print(genre, coca_genre_count[genre])\n",
    "    deleteDir(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sfu_review\n",
      "Movies\n",
      "CORE\n",
      "SOCC\n",
      "Cornell\n"
     ]
    }
   ],
   "source": [
    "total_word_counts = [['corpus', 'num_words']]\n",
    "genre_word_counts = [['corpus', 'genre', 'num_words']]\n",
    "\n",
    "path = 'pos/'\n",
    "suffix = '_pos.csv'\n",
    "\n",
    "# appends previously calculated COCA counts to the new array\n",
    "coca_all = 0\n",
    "for g in coca_genre_count:\n",
    "    genre_word_counts.append(['COCA', g, coca_genre_count[g]])\n",
    "    coca_all += coca_genre_count[g]\n",
    "total_word_counts.append(['COCA', coca_all])\n",
    "\n",
    "# iterates over all POS files to get word counts\n",
    "files = [ path+f for f in os.listdir(path) if f.endswith(suffix)]\n",
    "\n",
    "for f in files:\n",
    "    corpusname = f.split(path)[1].split(suffix)[0]\n",
    "    print(corpusname)\n",
    "    df = pd.read_csv(f)\n",
    "    \n",
    "    # throw out any null values (shouldn't be any)\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    # throw out anything that doesn't have at least one letter in it\n",
    "    df = df[~ df['token'].str.match('[^a-zA-Z]+$')]\n",
    "    \n",
    "    # genre counts where possible\n",
    "    if 'genre' in df.columns:\n",
    "        grouped = df.groupby('genre')\n",
    "        for genre,group in grouped:\n",
    "            genre_word_counts.append([corpusname, genre, len(group.index)])\n",
    "    \n",
    "    # number of words is just the length of this pruned dataframe, because every row has only one word\n",
    "    total_word_counts.append([corpusname, len(df.index)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['corpus', 'num_words'],\n",
       " ['COCA', 630147646],\n",
       " ['sfu_review', 255180],\n",
       " ['Movies', 3957840],\n",
       " ['CORE', 51452856],\n",
       " ['SOCC', 38046009],\n",
       " ['Cornell', 1281957]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['corpus', 'genre', 'num_words'],\n",
       " ['COCA', 'Academic', 120484732],\n",
       " ['COCA', 'News', 125553380],\n",
       " ['COCA', 'Spoken', 131059025],\n",
       " ['COCA', 'Magazine', 127689724],\n",
       " ['COCA', 'Fiction', 125360785],\n",
       " ['sfu_review', 'BOOKS', 25376],\n",
       " ['sfu_review', 'CARS', 47261],\n",
       " ['sfu_review', 'COMPUTERS', 40949],\n",
       " ['sfu_review', 'COOKWARE', 21119],\n",
       " ['sfu_review', 'HOTELS', 32257],\n",
       " ['sfu_review', 'MOVIES', 32207],\n",
       " ['sfu_review', 'MUSIC', 41813],\n",
       " ['sfu_review', 'PHONES', 14198],\n",
       " ['CORE', 'How-to / Instructional', 1656046],\n",
       " ['CORE', 'Information Description', 10949997],\n",
       " ['CORE', 'Information Persuasion', 1214201],\n",
       " ['CORE', 'Interactive Discussion', 2958960],\n",
       " ['CORE', 'Lyrical', 301283],\n",
       " ['CORE', 'Narrative', 17918383],\n",
       " ['CORE', 'Opinion', 15536270],\n",
       " ['CORE', 'Spoken', 917716]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_adv_adj_counts = [['corpus', 'adv_adj_counts']]\n",
    "genre_adv_adj_counts = [['corpus', 'genre', 'adv_adj_counts']]\n",
    "\n",
    "# number of adverbly adjectives is just the length of the file containing the list for each corpus / genre, as applicable\n",
    "\n",
    "basepath = 'adverbly_adjectives'\n",
    "files = []\n",
    "for corpus in os.listdir(basepath):\n",
    "    for f_or_d in os.listdir(basepath+'/'+corpus):\n",
    "        \n",
    "        # handle genres\n",
    "        if os.path.isdir(basepath+'/'+corpus+'/'+f_or_d):\n",
    "            genres_list = [basepath+'/'+corpus+'/'+f_or_d+'/'+f for f in os.listdir(basepath+'/'+corpus+'/'+f_or_d)]\n",
    "            corpus_count = 0\n",
    "            for f in genres_list:\n",
    "                genre = f.split(f_or_d+'/')[1].split('_pairs.csv')[0]\n",
    "                df = pd.read_csv(f)\n",
    "                genre_count = len(df.index)\n",
    "                genre_adv_adj_counts.append([corpus, genre, genre_count])\n",
    "                \n",
    "        # handle master lists for each corpus\n",
    "        else:\n",
    "            assert os.path.isfile(basepath+'/'+corpus+'/'+f_or_d)\n",
    "            file = basepath+'/'+corpus+'/'+f_or_d\n",
    "            df = pd.read_csv(file)\n",
    "            count = len(df.index)\n",
    "            total_adv_adj_counts.append([corpus, count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['corpus', 'adv_adj_counts'],\n",
       " ['Cornell', 4287],\n",
       " ['Movies', 15761],\n",
       " ['sfu_review', 596],\n",
       " ['COCA', 192751],\n",
       " ['SOCC', 31912],\n",
       " ['CORE', 42544]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_adv_adj_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['corpus', 'genre', 'adv_adj_counts'],\n",
       " ['sfu_review', 'HOTELS', 89],\n",
       " ['sfu_review', 'MOVIES', 95],\n",
       " ['sfu_review', 'BOOKS', 53],\n",
       " ['sfu_review', 'COOKWARE', 34],\n",
       " ['sfu_review', 'PHONES', 31],\n",
       " ['sfu_review', 'CARS', 139],\n",
       " ['sfu_review', 'COMPUTERS', 82],\n",
       " ['sfu_review', 'MUSIC', 112],\n",
       " ['COCA', 'Magazine', 75984],\n",
       " ['COCA', 'Academic', 63999],\n",
       " ['COCA', 'Fiction', 54574],\n",
       " ['COCA', 'News', 54082],\n",
       " ['COCA', 'Spoken', 34729],\n",
       " ['CORE', 'Interactive_Discussion', 3466],\n",
       " ['CORE', 'Information_Persuasion', 1901],\n",
       " ['CORE', 'Narrative', 17223],\n",
       " ['CORE', 'Opinion', 20581],\n",
       " ['CORE', 'Lyrical', 168],\n",
       " ['CORE', 'Information_Description', 11401],\n",
       " ['CORE', 'How-to__Instructional', 1868],\n",
       " ['CORE', 'Spoken', 1457]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_adv_adj_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_hapax_legomena_counts = [['corpus', 'hapax_legomena_counts']]\n",
    "genre_hapax_legomena_counts = [['corpus', 'genre', 'hapax_legomena_counts']]\n",
    "\n",
    "# number of adverbly adjectives is just the length of the file containing the list for each corpus / genre, as applicable\n",
    "\n",
    "basepath = 'hapax_legomena'\n",
    "files = []\n",
    "for corpus in os.listdir(basepath):\n",
    "    for f_or_d in os.listdir(basepath+'/'+corpus):\n",
    "        if os.path.isdir(basepath+'/'+corpus+'/'+f_or_d):\n",
    "            genres_list = [basepath+'/'+corpus+'/'+f_or_d+'/'+f for f in os.listdir(basepath+'/'+corpus+'/'+f_or_d)]\n",
    "            corpus_count = 0\n",
    "            for f in genres_list:\n",
    "                genre = f.split(f_or_d+'/')[1].split('_pairs.csv')[0]\n",
    "                df = pd.read_csv(f)\n",
    "                genre_count = len(df.index)\n",
    "                genre_hapax_legomena_counts.append([corpus, genre, genre_count])\n",
    "                \n",
    "        else:\n",
    "            assert os.path.isfile(basepath+'/'+corpus+'/'+f_or_d)\n",
    "            file = basepath+'/'+corpus+'/'+f_or_d\n",
    "            df = pd.read_csv(file)\n",
    "            count = len(df.index)\n",
    "            total_hapax_legomena_counts.append([corpus, count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['corpus', 'hapax_legomena_counts'],\n",
       " ['Cornell', 3710],\n",
       " ['Movies', 13977],\n",
       " ['sfu_review', 550],\n",
       " ['COCA', 128845],\n",
       " ['SOCC', 22022],\n",
       " ['CORE', 30276]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_hapax_legomena_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['corpus', 'genre', 'hapax_legomena_counts'],\n",
       " ['sfu_review', 'HOTELS', 86],\n",
       " ['sfu_review', 'MOVIES', 93],\n",
       " ['sfu_review', 'BOOKS', 52],\n",
       " ['sfu_review', 'COOKWARE', 31],\n",
       " ['sfu_review', 'PHONES', 28],\n",
       " ['sfu_review', 'CARS', 131],\n",
       " ['sfu_review', 'COMPUTERS', 79],\n",
       " ['sfu_review', 'MUSIC', 102],\n",
       " ['COCA', 'Magazine', 54816],\n",
       " ['COCA', 'Academic', 45509],\n",
       " ['COCA', 'Fiction', 41222],\n",
       " ['COCA', 'News', 39213],\n",
       " ['COCA', 'Spoken', 23138],\n",
       " ['CORE', 'Interactive_Discussion', 2535],\n",
       " ['CORE', 'Information_Persuasion', 1522],\n",
       " ['CORE', 'Narrative', 13011],\n",
       " ['CORE', 'Opinion', 15686],\n",
       " ['CORE', 'Lyrical', 152],\n",
       " ['CORE', 'Information_Description', 8812],\n",
       " ['CORE', 'How-to__Instructional', 1570],\n",
       " ['CORE', 'Spoken', 1236]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_hapax_legomena_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting all arrays to dataframes for quick and easy calculations later\n",
    "\n",
    "df1 = pd.DataFrame(total_word_counts[1:], columns=total_word_counts[0])\n",
    "df2 = pd.DataFrame(total_adv_adj_counts[1:], columns=total_adv_adj_counts[0])\n",
    "df3 = pd.DataFrame(total_hapax_legomena_counts[1:], columns=total_hapax_legomena_counts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "      <th>num_words</th>\n",
       "      <th>adv_adj_counts</th>\n",
       "      <th>hapax_legomena_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COCA</td>\n",
       "      <td>630147646</td>\n",
       "      <td>192751</td>\n",
       "      <td>128845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sfu_review</td>\n",
       "      <td>255180</td>\n",
       "      <td>596</td>\n",
       "      <td>550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Movies</td>\n",
       "      <td>3957840</td>\n",
       "      <td>15761</td>\n",
       "      <td>13977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CORE</td>\n",
       "      <td>51452856</td>\n",
       "      <td>42544</td>\n",
       "      <td>30276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SOCC</td>\n",
       "      <td>38046009</td>\n",
       "      <td>31912</td>\n",
       "      <td>22022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cornell</td>\n",
       "      <td>1281957</td>\n",
       "      <td>4287</td>\n",
       "      <td>3710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       corpus  num_words  adv_adj_counts  hapax_legomena_counts\n",
       "0        COCA  630147646          192751                 128845\n",
       "1  sfu_review     255180             596                    550\n",
       "2      Movies    3957840           15761                  13977\n",
       "3        CORE   51452856           42544                  30276\n",
       "4        SOCC   38046009           31912                  22022\n",
       "5     Cornell    1281957            4287                   3710"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge all dataframes into one big one\n",
    "\n",
    "corpus_df = df1.merge(df2, on='corpus').merge(df3, on='corpus')\n",
    "corpus_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate relative frequencies\n",
    "\n",
    "corpus_df['adv_adj_freqmil'] = corpus_df['adv_adj_counts'] / corpus_df['num_words'] * 1000000\n",
    "corpus_df['hapax_legomena_freqmil'] = corpus_df['hapax_legomena_counts'] / corpus_df['num_words'] * 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "      <th>num_words</th>\n",
       "      <th>adv_adj_counts</th>\n",
       "      <th>hapax_legomena_counts</th>\n",
       "      <th>adv_adj_freqmil</th>\n",
       "      <th>hapax_legomena_freqmil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COCA</td>\n",
       "      <td>630147646</td>\n",
       "      <td>192751</td>\n",
       "      <td>128845</td>\n",
       "      <td>305.882282</td>\n",
       "      <td>204.467954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sfu_review</td>\n",
       "      <td>255180</td>\n",
       "      <td>596</td>\n",
       "      <td>550</td>\n",
       "      <td>2335.606239</td>\n",
       "      <td>2155.341328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Movies</td>\n",
       "      <td>3957840</td>\n",
       "      <td>15761</td>\n",
       "      <td>13977</td>\n",
       "      <td>3982.222626</td>\n",
       "      <td>3531.471712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CORE</td>\n",
       "      <td>51452856</td>\n",
       "      <td>42544</td>\n",
       "      <td>30276</td>\n",
       "      <td>826.854004</td>\n",
       "      <td>588.422147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SOCC</td>\n",
       "      <td>38046009</td>\n",
       "      <td>31912</td>\n",
       "      <td>22022</td>\n",
       "      <td>838.773917</td>\n",
       "      <td>578.825495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cornell</td>\n",
       "      <td>1281957</td>\n",
       "      <td>4287</td>\n",
       "      <td>3710</td>\n",
       "      <td>3344.105926</td>\n",
       "      <td>2894.012826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       corpus  num_words  adv_adj_counts  hapax_legomena_counts  \\\n",
       "0        COCA  630147646          192751                 128845   \n",
       "1  sfu_review     255180             596                    550   \n",
       "2      Movies    3957840           15761                  13977   \n",
       "3        CORE   51452856           42544                  30276   \n",
       "4        SOCC   38046009           31912                  22022   \n",
       "5     Cornell    1281957            4287                   3710   \n",
       "\n",
       "   adv_adj_freqmil  hapax_legomena_freqmil  \n",
       "0       305.882282              204.467954  \n",
       "1      2335.606239             2155.341328  \n",
       "2      3982.222626             3531.471712  \n",
       "3       826.854004              588.422147  \n",
       "4       838.773917              578.825495  \n",
       "5      3344.105926             2894.012826  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same process for genres\n",
    "\n",
    "df1 = pd.DataFrame(genre_word_counts[1:], columns=genre_word_counts[0])\n",
    "df2 = pd.DataFrame(genre_adv_adj_counts[1:], columns=genre_adv_adj_counts[0])\n",
    "df3 = pd.DataFrame(genre_hapax_legomena_counts[1:], columns=genre_hapax_legomena_counts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "      <th>genre</th>\n",
       "      <th>num_words</th>\n",
       "      <th>adv_adj_counts</th>\n",
       "      <th>hapax_legomena_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COCA</td>\n",
       "      <td>Academic</td>\n",
       "      <td>120484732</td>\n",
       "      <td>63999</td>\n",
       "      <td>45509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COCA</td>\n",
       "      <td>News</td>\n",
       "      <td>125553380</td>\n",
       "      <td>54082</td>\n",
       "      <td>39213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COCA</td>\n",
       "      <td>Spoken</td>\n",
       "      <td>131059025</td>\n",
       "      <td>34729</td>\n",
       "      <td>23138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COCA</td>\n",
       "      <td>Magazine</td>\n",
       "      <td>127689724</td>\n",
       "      <td>75984</td>\n",
       "      <td>54816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COCA</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>125360785</td>\n",
       "      <td>54574</td>\n",
       "      <td>41222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sfu_review</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>25376</td>\n",
       "      <td>53</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sfu_review</td>\n",
       "      <td>CARS</td>\n",
       "      <td>47261</td>\n",
       "      <td>139</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sfu_review</td>\n",
       "      <td>COMPUTERS</td>\n",
       "      <td>40949</td>\n",
       "      <td>82</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sfu_review</td>\n",
       "      <td>COOKWARE</td>\n",
       "      <td>21119</td>\n",
       "      <td>34</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sfu_review</td>\n",
       "      <td>HOTELS</td>\n",
       "      <td>32257</td>\n",
       "      <td>89</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sfu_review</td>\n",
       "      <td>MOVIES</td>\n",
       "      <td>32207</td>\n",
       "      <td>95</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sfu_review</td>\n",
       "      <td>MUSIC</td>\n",
       "      <td>41813</td>\n",
       "      <td>112</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sfu_review</td>\n",
       "      <td>PHONES</td>\n",
       "      <td>14198</td>\n",
       "      <td>31</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CORE</td>\n",
       "      <td>Lyrical</td>\n",
       "      <td>301283</td>\n",
       "      <td>168</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CORE</td>\n",
       "      <td>Narrative</td>\n",
       "      <td>17918383</td>\n",
       "      <td>17223</td>\n",
       "      <td>13011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CORE</td>\n",
       "      <td>Opinion</td>\n",
       "      <td>15536270</td>\n",
       "      <td>20581</td>\n",
       "      <td>15686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CORE</td>\n",
       "      <td>Spoken</td>\n",
       "      <td>917716</td>\n",
       "      <td>1457</td>\n",
       "      <td>1236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        corpus      genre  num_words  adv_adj_counts  hapax_legomena_counts\n",
       "0         COCA   Academic  120484732           63999                  45509\n",
       "1         COCA       News  125553380           54082                  39213\n",
       "2         COCA     Spoken  131059025           34729                  23138\n",
       "3         COCA   Magazine  127689724           75984                  54816\n",
       "4         COCA    Fiction  125360785           54574                  41222\n",
       "5   sfu_review      BOOKS      25376              53                     52\n",
       "6   sfu_review       CARS      47261             139                    131\n",
       "7   sfu_review  COMPUTERS      40949              82                     79\n",
       "8   sfu_review   COOKWARE      21119              34                     31\n",
       "9   sfu_review     HOTELS      32257              89                     86\n",
       "10  sfu_review     MOVIES      32207              95                     93\n",
       "11  sfu_review      MUSIC      41813             112                    102\n",
       "12  sfu_review     PHONES      14198              31                     28\n",
       "13        CORE    Lyrical     301283             168                    152\n",
       "14        CORE  Narrative   17918383           17223                  13011\n",
       "15        CORE    Opinion   15536270           20581                  15686\n",
       "16        CORE     Spoken     917716            1457                   1236"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_df = df1.merge(df2, on=['corpus', 'genre']).merge(df3, on=['corpus', 'genre'])#.merge(df4, on=['corpus', 'genre'])\n",
    "genre_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_df['adv_adj_freqmil'] = genre_df['adv_adj_counts'] / genre_df['num_words'] * 1000000\n",
    "genre_df['hapax_legomena_freqmil'] = genre_df['hapax_legomena_counts'] / genre_df['num_words'] * 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "      <th>genre</th>\n",
       "      <th>num_words</th>\n",
       "      <th>adv_adj_counts</th>\n",
       "      <th>hapax_legomena_counts</th>\n",
       "      <th>adv_adj_freqmil</th>\n",
       "      <th>hapax_legomena_freqmil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COCA</td>\n",
       "      <td>Academic</td>\n",
       "      <td>120484732</td>\n",
       "      <td>63999</td>\n",
       "      <td>45509</td>\n",
       "      <td>531.179336</td>\n",
       "      <td>377.715908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COCA</td>\n",
       "      <td>News</td>\n",
       "      <td>125553380</td>\n",
       "      <td>54082</td>\n",
       "      <td>39213</td>\n",
       "      <td>430.749057</td>\n",
       "      <td>312.321341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COCA</td>\n",
       "      <td>Spoken</td>\n",
       "      <td>131059025</td>\n",
       "      <td>34729</td>\n",
       "      <td>23138</td>\n",
       "      <td>264.987474</td>\n",
       "      <td>176.546407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COCA</td>\n",
       "      <td>Magazine</td>\n",
       "      <td>127689724</td>\n",
       "      <td>75984</td>\n",
       "      <td>54816</td>\n",
       "      <td>595.067462</td>\n",
       "      <td>429.290614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COCA</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>125360785</td>\n",
       "      <td>54574</td>\n",
       "      <td>41222</td>\n",
       "      <td>435.335500</td>\n",
       "      <td>328.826913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sfu_review</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>25376</td>\n",
       "      <td>53</td>\n",
       "      <td>52</td>\n",
       "      <td>2088.587642</td>\n",
       "      <td>2049.180328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sfu_review</td>\n",
       "      <td>CARS</td>\n",
       "      <td>47261</td>\n",
       "      <td>139</td>\n",
       "      <td>131</td>\n",
       "      <td>2941.114238</td>\n",
       "      <td>2771.841476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sfu_review</td>\n",
       "      <td>COMPUTERS</td>\n",
       "      <td>40949</td>\n",
       "      <td>82</td>\n",
       "      <td>79</td>\n",
       "      <td>2002.490903</td>\n",
       "      <td>1929.229041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sfu_review</td>\n",
       "      <td>COOKWARE</td>\n",
       "      <td>21119</td>\n",
       "      <td>34</td>\n",
       "      <td>31</td>\n",
       "      <td>1609.924712</td>\n",
       "      <td>1467.872532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sfu_review</td>\n",
       "      <td>HOTELS</td>\n",
       "      <td>32257</td>\n",
       "      <td>89</td>\n",
       "      <td>86</td>\n",
       "      <td>2759.091050</td>\n",
       "      <td>2666.087981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sfu_review</td>\n",
       "      <td>MOVIES</td>\n",
       "      <td>32207</td>\n",
       "      <td>95</td>\n",
       "      <td>93</td>\n",
       "      <td>2949.669327</td>\n",
       "      <td>2887.571025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sfu_review</td>\n",
       "      <td>MUSIC</td>\n",
       "      <td>41813</td>\n",
       "      <td>112</td>\n",
       "      <td>102</td>\n",
       "      <td>2678.592782</td>\n",
       "      <td>2439.432712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sfu_review</td>\n",
       "      <td>PHONES</td>\n",
       "      <td>14198</td>\n",
       "      <td>31</td>\n",
       "      <td>28</td>\n",
       "      <td>2183.406114</td>\n",
       "      <td>1972.108748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CORE</td>\n",
       "      <td>Lyrical</td>\n",
       "      <td>301283</td>\n",
       "      <td>168</td>\n",
       "      <td>152</td>\n",
       "      <td>557.615265</td>\n",
       "      <td>504.509050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CORE</td>\n",
       "      <td>Narrative</td>\n",
       "      <td>17918383</td>\n",
       "      <td>17223</td>\n",
       "      <td>13011</td>\n",
       "      <td>961.191643</td>\n",
       "      <td>726.125789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CORE</td>\n",
       "      <td>Opinion</td>\n",
       "      <td>15536270</td>\n",
       "      <td>20581</td>\n",
       "      <td>15686</td>\n",
       "      <td>1324.706638</td>\n",
       "      <td>1009.637448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CORE</td>\n",
       "      <td>Spoken</td>\n",
       "      <td>917716</td>\n",
       "      <td>1457</td>\n",
       "      <td>1236</td>\n",
       "      <td>1587.637134</td>\n",
       "      <td>1346.821893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        corpus      genre  num_words  adv_adj_counts  hapax_legomena_counts  \\\n",
       "0         COCA   Academic  120484732           63999                  45509   \n",
       "1         COCA       News  125553380           54082                  39213   \n",
       "2         COCA     Spoken  131059025           34729                  23138   \n",
       "3         COCA   Magazine  127689724           75984                  54816   \n",
       "4         COCA    Fiction  125360785           54574                  41222   \n",
       "5   sfu_review      BOOKS      25376              53                     52   \n",
       "6   sfu_review       CARS      47261             139                    131   \n",
       "7   sfu_review  COMPUTERS      40949              82                     79   \n",
       "8   sfu_review   COOKWARE      21119              34                     31   \n",
       "9   sfu_review     HOTELS      32257              89                     86   \n",
       "10  sfu_review     MOVIES      32207              95                     93   \n",
       "11  sfu_review      MUSIC      41813             112                    102   \n",
       "12  sfu_review     PHONES      14198              31                     28   \n",
       "13        CORE    Lyrical     301283             168                    152   \n",
       "14        CORE  Narrative   17918383           17223                  13011   \n",
       "15        CORE    Opinion   15536270           20581                  15686   \n",
       "16        CORE     Spoken     917716            1457                   1236   \n",
       "\n",
       "    adv_adj_freqmil  hapax_legomena_freqmil  \n",
       "0        531.179336              377.715908  \n",
       "1        430.749057              312.321341  \n",
       "2        264.987474              176.546407  \n",
       "3        595.067462              429.290614  \n",
       "4        435.335500              328.826913  \n",
       "5       2088.587642             2049.180328  \n",
       "6       2941.114238             2771.841476  \n",
       "7       2002.490903             1929.229041  \n",
       "8       1609.924712             1467.872532  \n",
       "9       2759.091050             2666.087981  \n",
       "10      2949.669327             2887.571025  \n",
       "11      2678.592782             2439.432712  \n",
       "12      2183.406114             1972.108748  \n",
       "13       557.615265              504.509050  \n",
       "14       961.191643              726.125789  \n",
       "15      1324.706638             1009.637448  \n",
       "16      1587.637134             1346.821893  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write results to 2 CSV files\n",
    "\n",
    "corpus_df.to_csv('corpus_stats.csv', index=None)\n",
    "genre_df.to_csv('genre_stats.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
