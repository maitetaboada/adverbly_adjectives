{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = 'adverbly_adjectives'\n",
    "os.makedirs(basepath, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractAdverblyAdjectives(corpusname, textnums, tokens, pos, genres=pd.DataFrame(), decades=pd.DataFrame(), bygenre=True, bydecade=False):\n",
    "    assert tokens.shape == textnums.shape, \"Tokens must be the same length as the text numbers\"\n",
    "    assert textnums.shape == pos.shape, \"Parts of speech must be the same length as the text numbers\"\n",
    "    if bygenre:\n",
    "        assert genres.shape == tokens.shape, \"Genres must be the same length as the number of texts\"\n",
    "    if bydecade:\n",
    "        assert decades.shape == tokens.shape, \"Decades must be the same length as the number of texts\"\n",
    "    \n",
    "    print(corpusname)\n",
    "    \n",
    "    corpuspath = basepath + '/' + corpusname \n",
    "    os.makedirs(corpuspath, exist_ok=True)\n",
    "    \n",
    "    if bygenre:\n",
    "        df = pd.concat([genres, textnums, tokens, pos], axis=1)\n",
    "        print(df.head())\n",
    "    else:\n",
    "        df = pd.concat([textnums, tokens, pos], axis=1)\n",
    "    \n",
    "    if bygenre:\n",
    "        \n",
    "        genrespath = corpuspath + '/' + 'genres'\n",
    "        os.makedirs(genrespath, exist_ok=True)\n",
    "        \n",
    "        genre_grouped = df.groupby('genre')\n",
    "        \n",
    "        for genre,genre_group in genre_grouped:\n",
    "            num_tokens = len(genre_group.index)\n",
    "            print(genre, num_tokens)\n",
    "            \n",
    "            grouped = genre_group.groupby('text_num')\n",
    "            \n",
    "            genre_df = pd.DataFrame()\n",
    "\n",
    "            for name,group in grouped:\n",
    "                next_pos = group['pos'][1:].reset_index(drop=True).rename('next_pos')\n",
    "                next_token = group['token'][1:].reset_index(drop=True).rename('next_token')\n",
    "        \n",
    "                group = group.reset_index(drop=True)\n",
    "\n",
    "                # Throw out last word\n",
    "                group = pd.concat([group, next_pos, next_token], axis=1).dropna()\n",
    "                \n",
    "                # Keep only fully alphabetical words\n",
    "                group = group[group['token'].str.isalpha() & group['next_token'].str.isalpha()]\n",
    "                \n",
    "                # Keep only the pairs where the first token ends in ly\n",
    "                group = group[group['token'].str.endswith('ly')]\n",
    "                \n",
    "                # Throw out 'only'\n",
    "                group = group[group['token'] != 'only']\n",
    "                \n",
    "                # Adverbly adjectives!\n",
    "                group = group[(group['pos'] == 'ADV') & (group['next_pos'] == 'ADJ')]\n",
    "                \n",
    "                pair = group['token'].str.cat(group['next_token'], sep=' ').rename('pair')\n",
    "                \n",
    "                genre_df = pd.concat([genre_df, pair], axis=0)\n",
    "            \n",
    "            genre_df = genre_df.rename(columns={0 : 'pairs'})\n",
    "            genre = re.sub('/', '', re.sub(' ', '_', genre))\n",
    "            \n",
    "            final_df = genre_df['pairs'].value_counts().reset_index()\n",
    "            final_df['freqmil'] = (final_df['pairs'] / num_tokens) * 1000000\n",
    "            \n",
    "            final_df.to_csv(genrespath + '/' + genre + '_pairs.csv', header=['pair', 'counts', 'freqmil'], index=None)\n",
    "                \n",
    "    num_tokens = len(df.index)\n",
    "    print(corpusname, num_tokens)\n",
    "\n",
    "    grouped = df.groupby('text_num')\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for name,group in grouped:\n",
    "        next_pos = group['pos'][1:].reset_index(drop=True).rename('next_pos')\n",
    "        next_token = group['token'][1:].reset_index(drop=True).rename('next_token')\n",
    "\n",
    "        group = group.reset_index(drop=True)\n",
    "\n",
    "        # Throw out last word\n",
    "        group = pd.concat([group, next_pos, next_token], axis=1).dropna()\n",
    "\n",
    "        # Keep only fully alphabetical words\n",
    "        group = group[group['token'].str.isalpha() & group['next_token'].str.isalpha()]\n",
    "\n",
    "        # Keep only the pairs where the first token ends in ly\n",
    "        group = group[group['token'].str.endswith('ly')]\n",
    "\n",
    "        # Throw out 'only'\n",
    "        group = group[group['token'] != 'only']\n",
    "\n",
    "        # Adverbly adjectives!\n",
    "        group = group[(group['pos'] == 'ADV') & (group['next_pos'] == 'ADJ')]\n",
    "\n",
    "        pair = group['token'].str.cat(group['next_token'], sep=' ').rename('pair')\n",
    "\n",
    "        df = pd.concat([df, pair], axis=0)\n",
    "\n",
    "    df = df.rename(columns={0 : 'pairs'})\n",
    "    final_df = df['pairs'].value_counts().reset_index()\n",
    "    final_df['freqmil'] = (final_df['pairs'] / num_tokens) * 1000000\n",
    "\n",
    "    final_df.to_csv(corpuspath + '/' + 'all_pairs.csv', header=['pair', 'counts', 'freqmil'], index=None)\n",
    "    \n",
    "    if bydecade:\n",
    "        df = pd.concat([decades, textnums, tokens, pos], axis=1)\n",
    "#         print(df.head())\n",
    "        \n",
    "        decadespath = corpuspath + '/' + 'decades'\n",
    "        os.makedirs(decadespath, exist_ok=True)\n",
    "        \n",
    "        decade_grouped = df.groupby('decade')\n",
    "        \n",
    "        for decade,decade_group in decade_grouped:\n",
    "            num_tokens = len(decade_group.index)\n",
    "            print(decade, num_tokens)\n",
    "            \n",
    "            grouped = decade_group.groupby('text_num')\n",
    "            \n",
    "            decade_df = pd.DataFrame()\n",
    "\n",
    "            for name,group in grouped:\n",
    "                next_pos = group['pos'][1:].reset_index(drop=True).rename('next_pos')\n",
    "                next_token = group['token'][1:].reset_index(drop=True).rename('next_token')\n",
    "        \n",
    "                group = group.reset_index(drop=True)\n",
    "\n",
    "                # Throw out last word\n",
    "                group = pd.concat([group, next_pos, next_token], axis=1).dropna()\n",
    "                \n",
    "                # Keep only fully alphabetical words\n",
    "                group = group[group['token'].str.isalpha() & group['next_token'].str.isalpha()]\n",
    "                \n",
    "                # Keep only the pairs where the first token ends in ly\n",
    "                group = group[group['token'].str.endswith('ly')]\n",
    "                \n",
    "                # Throw out 'only'\n",
    "                group = group[group['token'] != 'only']\n",
    "                \n",
    "                # Adverbly adjectives!\n",
    "                group = group[(group['pos'] == 'ADV') & (group['next_pos'] == 'ADJ')]\n",
    "                \n",
    "                pair = group['token'].str.cat(group['next_token'], sep=' ').rename('pair')\n",
    "                \n",
    "                decade_df = pd.concat([decade_df, pair], axis=0)\n",
    "            \n",
    "            decade_df = decade_df.rename(columns={0 : 'pairs'})\n",
    "            decade = re.sub('/', '', re.sub(' ', '_', str(decade)))\n",
    "            \n",
    "            final_df = decade_df['pairs'].value_counts().reset_index()\n",
    "            final_df['freqmil'] = (final_df['pairs'] / num_tokens) * 1000000\n",
    "            \n",
    "            final_df.to_csv(decadespath + '/' + decade + '_pairs.csv', header=['pair', 'counts', 'freqmil'], index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   decade  text_num       token    pos\n",
      "0    1948         0       greed  PROPN\n",
      "1    1948         0           ,  PUNCT\n",
      "2    1948         0           a    DET\n",
      "3    1948         0  despicable    ADJ\n",
      "4    1948         0     passion   NOUN\n",
      "NYT\n",
      "NYT 20575297\n",
      "1915 795\n",
      "1916 983\n",
      "1921 1162\n",
      "1923 391\n",
      "1924 48614\n",
      "1925 202222\n",
      "1926 119628\n",
      "1927 102127\n",
      "1928 167784\n",
      "1929 193270\n",
      "1930 173256\n",
      "1931 215076\n",
      "1932 250815\n",
      "1933 239777\n",
      "1934 213126\n",
      "1935 194373\n",
      "1936 224176\n",
      "1937 69146\n",
      "1938 64737\n",
      "1939 169201\n",
      "1940 185330\n",
      "1941 149091\n",
      "1942 134011\n",
      "1943 111442\n",
      "1944 121652\n",
      "1945 76093\n",
      "1946 90088\n",
      "1947 134190\n",
      "1948 140651\n",
      "1949 174168\n",
      "1950 129915\n",
      "1951 123651\n",
      "1952 171599\n",
      "1953 162222\n",
      "1954 141405\n",
      "1955 121238\n",
      "1956 101544\n",
      "1957 114714\n",
      "1958 139102\n",
      "1959 136992\n",
      "1960 115790\n",
      "1961 115837\n",
      "1962 105139\n",
      "1963 100476\n",
      "1964 135969\n",
      "1965 120305\n",
      "1966 98243\n",
      "1967 104932\n",
      "1968 145024\n",
      "1969 163157\n",
      "1970 107072\n",
      "1971 154019\n",
      "1972 123073\n",
      "1973 117898\n",
      "1974 96426\n",
      "1975 82532\n",
      "1976 101426\n",
      "1977 109918\n",
      "1978 123407\n",
      "1979 192496\n",
      "1980 10573\n",
      "1981 187622\n",
      "1982 215695\n",
      "1983 211342\n",
      "1984 207822\n",
      "1985 237325\n",
      "1986 268761\n",
      "1987 291479\n",
      "1988 302797\n",
      "1989 248341\n",
      "1990 258925\n",
      "1991 300393\n",
      "1992 309842\n",
      "1993 312202\n",
      "1994 304207\n",
      "1995 294673\n",
      "1996 318752\n",
      "1997 326139\n",
      "1998 341862\n",
      "1999 357002\n",
      "2000 423494\n",
      "2001 419120\n",
      "2002 461520\n",
      "2003 381650\n",
      "2004 240081\n",
      "2005 8499\n",
      "2006 332774\n",
      "2007 441030\n",
      "2008 440867\n",
      "2009 447543\n",
      "2010 464705\n",
      "2011 525438\n",
      "2012 427701\n",
      "2013 438445\n",
      "2014 467481\n",
      "2015 441631\n",
      "2016 423200\n",
      "2017 373245\n",
      "2018 374377\n",
      "2019 13846\n"
     ]
    }
   ],
   "source": [
    "path = 'pos/'\n",
    "suffix = '_pos.csv'\n",
    "\n",
    "files = [ path+f for f in os.listdir(path) if f.endswith(suffix)]\n",
    "\n",
    "for f in files:\n",
    "    corpusname = f.split(path)[1].split(suffix)[0]\n",
    "    df = pd.read_csv(f)\n",
    "    \n",
    "    df['token'] = df['token'].str.lower()\n",
    "    \n",
    "    print(df.head())\n",
    "    \n",
    "    if 'genre' in df.columns:\n",
    "        extractAdverblyAdjectives(corpusname, df['text_num'], df['token'], df['pos'], df['genre'],\n",
    "                                  bygenre=True, bydecade=False)\n",
    "        if 'decade' in df.columns:\n",
    "            extractAdverblyAdjectives(corpusname, df['text_num'], df['token'], df['pos'], df['genre'], df['decade'],\n",
    "                                      bygenre=True, bydecade=True)\n",
    "    elif 'decade' in df.columns:\n",
    "            extractAdverblyAdjectives(corpusname, df['text_num'], df['token'], df['pos'], decades=df['decade'],\n",
    "                                      bygenre=False, bydecade=True)\n",
    "    else:\n",
    "        extractAdverblyAdjectives(corpusname, df['text_num'], df['token'], df['pos'],\n",
    "                                 bygenre=False, bydecade=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specially dealing with COCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_dict = {\n",
    "    'spok' : 'Spoken',\n",
    "    'mag' : 'Magazine',\n",
    "    'acad' : 'Academic',\n",
    "    'news' : 'News',\n",
    "    'fic' : 'Fiction'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_path = 'COCA/POS/'\n",
    "zipfiles = [pos_path+f for f in os.listdir(pos_path) if f.endswith('.zip')]\n",
    "print(zipfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deleteDir(dir):\n",
    "    try:\n",
    "        for f in os.listdir(dir):\n",
    "            os.remove(dir+f)\n",
    "        os.rmdir(dir)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "genre_count = defaultdict(int)\n",
    "\n",
    "tmp_dir = '__tmp/'\n",
    "\n",
    "deleteDir(tmp_dir)\n",
    "\n",
    "for f in zipfiles:\n",
    "    os.makedirs(tmp_dir)\n",
    "    \n",
    "    genre = genre_dict[f.split('/')[-1].split('.zip')[0]]\n",
    "    with ZipFile(f, 'r') as zip_f:\n",
    "        zip_f.extractall(tmp_dir)\n",
    "    \n",
    "    lines = 0\n",
    "    for f in os.listdir(tmp_dir):\n",
    "        with open(tmp_dir+f, 'r', encoding='latin-1') as fo:\n",
    "            for l in fo:\n",
    "                if not l.startswith('##'):\n",
    "                    lines += 1\n",
    "    \n",
    "    genre_count[genre] = lines\n",
    "    \n",
    "    print(genre, genre_count[genre])\n",
    "    deleteDir(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advadj_path = 'COCA/all_years/'\n",
    "corpusname = 'COCA'\n",
    "\n",
    "advadj_files = [advadj_path+f for f in os.listdir(advadj_path) if f.endswith('.csv')]\n",
    "\n",
    "for f in advadj_files:\n",
    "    allGenres = False\n",
    "    \n",
    "    split = f.split('/')[-1].split('.csv')[0].split('_')\n",
    "    if len(split) == 3:\n",
    "        genre = genre_dict[split[0]]\n",
    "    else:\n",
    "        allGenres = True\n",
    "    \n",
    "    df = pd.read_csv(f).rename(columns={'freq' : 'counts'})\n",
    "    \n",
    "    num_tokens = -1\n",
    "    if allGenres:\n",
    "        num_tokens = sum([genre_count[g] for g in genre_count])\n",
    "    else:\n",
    "        num_tokens = genre_count[genre]\n",
    "    \n",
    "    df['freqmil'] = (df['counts'] / num_tokens) * 1000000\n",
    "    \n",
    "    df.sort_values('counts', ascending=False, inplace=True)\n",
    "    \n",
    "    # Keep only fully alphabetical words\n",
    "    df = df[df['pair'].str.match('[a-zA-Z ]*')]\n",
    "\n",
    "    # Throw out 'only'\n",
    "    df = df[~ df['pair'].str.startswith('only ')]\n",
    "    \n",
    "    corpuspath = basepath + '/' + corpusname \n",
    "    os.makedirs(corpuspath, exist_ok=True)\n",
    "    \n",
    "    genrespath = corpuspath + '/' + 'genres'\n",
    "    os.makedirs(genrespath, exist_ok=True)\n",
    "    \n",
    "    if allGenres:\n",
    "        df.to_csv(corpuspath + '/' + 'all_pairs.csv', header=['pair', 'counts', 'freqmil'], index=None)\n",
    "    else:\n",
    "        print(genre)\n",
    "        df.to_csv(genrespath + '/' + genre + '_pairs.csv', header=['pair', 'counts', 'freqmil'], index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
